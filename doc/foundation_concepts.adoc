:toc:
:toc-placement!:
:toclevels: 4

ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

= Foundation concepts

toc::[]

== General overview of ecosystem for getting data into CollectionSpace

The data wrangling stack for CollectionSpace is pretty complex at this point.

Almost all of the tooling for working with CS data outside the actual application or API is written in Ruby.

The following applications may be involved:

=== CollectionSpace Services API

Part of core CollectionSpace: https://github.com/collectionspace/services

https://collectionspace.atlassian.net/wiki/spaces/cstd/pages/3577544705/Common+Services+REST+API[Documentation]

In the data wrangling stack, we use the API to

* create, update, or delete records in an instance by sending an XML record payload.
* retrieve underlying identifiers of authority and vocabulary terms used in building CS XML
* retrieve information about the status of records

=== collectionspace-client

Provides:

* method for connecting/authenticating to a CS instance
* convenience wrappers around the CollectionSpace Services API functionalityK, including CRUD and search

=== collectionspace-refcache

Provides consistent syntactic sugar for using a Zache-, Redis-, or ActiveSupport-based cache to store pieces of data about CS entities (authority terms, vocabulary terms, objects, procedures, and relations) for efficient retrieval

=== cspace-config-untangler

*Input*

JSON UI config output from CollectionSpace instances (https://core.collectionspace.org/cspace/core/config[example])

IMPORTANT: This tool only works reliably with CollectionSpace version 6.1 and above

*Outputs include:*

* a set of JSON "xref:record-mapper[record mappers]"---one record mapper per record type in the profile.
* a set of CSV templates (one template for record type) for preparing data for import
* a CSV listing all the info on all the fields (contains everything in the old DDD-hand curated "schema" spreadsheets except the field usage notes/descriptions and the database-related columns). Examples for each CollectionSpace release are available in https://github.com/collectionspace/cspace-config-untangler/tree/main/data[the application's `data` directory, beginning with `all_fields_`]
* a CSV diff of two specified profiles, which make it easy to see what fields are present/lacking, and any differences in how fields are defined and labeled.

This is a command-line application. The README contains important setup information and assumption explanation. There is https://github.com/collectionspace/cspace-config-untangler/tree/main/doc[some common workflow documentation]. Most of the available commands are best documented in the CLI interface.

=== collectionspace-mapper

* Provides some CollectionSpace-specific data validation
* Converts a <<data hash,hash of data>> into CS XML.

Returns a `CollectionSpace::Mapper::Response` object that wraps the resulting XML, as well as any errors or warnings raised in the mapping process, and information on the record status in the given CS instance. If it is an existing record, the `Response` includes the record csid and uri for use in any subsequent API calls on the record.

Provides powerful, flexible https://github.com/collectionspace/collectionspace-mapper/blob/main/doc/batch_configuration.adoc[configuration options].

The general idea of how it works can be found in the https://github.com/collectionspace/collectionspace-mapper/blob/main/doc/usage.adoc[Usage docs].

Requires a <<record mapper>> generated by `cspace-config-untangler`.

Uses `collectionspace-refcache` to interact with a refname cache and a csid cache.

Uses `collectionspace-client` to check record status, lookup uncached authority/vocabulary term refnames, process some dates, and get other necessary info from the instance.


=== collectionspace-csv-importer

A webapp with a friendly user interface that lets non-technical folks:

* specify a connection to a CS instance (one time setup);
* create a batch by uploading a CSV;
* derive CS XML from the CSV rows (powered by `collectionspace-mapper`); and
* transfer the records derived from the CSV data into the connected CS instance (powered by `collectionspace-client`)

Basically everything is done via API call to ensure data integrity since this tool is mainly intended for users working in their own production CS instances, which may be changing during the process of mapping/transferring data.

This means it is pretty slow. Contrast with `collectionspace_migration_tools` which is much faster, but makes very different assumptions.

=== CollectionSpace Data Toolkit

Successor to collectionspace-csv-importer. In development

https://github.com/dts-hosting/data-toolkit

Will support additional data-oriented tasks beyond creation/update/deletion of records.

=== collectionspace_migration_tools

https://github.com/lyrasis/collectionspace_migration_tools

[IMPORTANT]
====
**This application is created and maintained for internal LYRASIS staff use only.** Many of its design decisions are based on:

* our CS hosting/deployment infrastructure
* the assumption that it will be used by data migration experts on migration projects where the target CS instance is not in active use

This means:

* it is *highly unlikely* anyone outside LYRASIS will be able to clone this repository and use the tool as-is
* using this tool on a CS instance in active use is **dangerous to the data integrity of that instance**

However, we have made this code available in the spirit of open-source and transparency, in case any of it might be informative for CS institutions/users who wish to build their own tooling for working with CS data at scale.
====

A command-line application for working with CS data at scale.

Its main functionality is the same as `collectionspace-csv-importer`, but it makes very different assumptions, mainly:

* the person using the tool can connect directly to the CS instance's database
* the CS instance is not in active use or being modified by anyone other than the person using the tool
* there is an AWS S3 bucket set up for importing data into the CS instance: when an object is uploaded into the bucket, it triggers an AWS Lambda process to ingest the record via API call

Given the above assumptions, for the mapping process, it:

- queries the DB to retrieve all refname and csid information necessary to map CSV data to CS XML and determine record status;
- caches the retrieved data; and
- instructs `collectionspace-mapper` to determine record status via cache rather than API call

For the record transfer process, the assumption that no one is working in an instance means we do not have to be mindful of performance implications of hammering the services API.

It has additional functionality such as generating frequently-needed reports, ingesting vocabulary/dynamic term list terms, and the in-progress Term Manager functionality.

=== cspace_hosted_instance_access (CHIA)

https://github.com/dts-hosting/cspace_hosted_instance_access

Wraps up logic for the following for reuse in cspace-config-untangler, collectionspace_migration_tools, or other tools used interally by Lyrasis staff:

* Get list of deployed tenant names
* Retrieve admin password parameter for each tenant from SSM
* Build instance URLs (base, services, config) with correct subdomain
* Retrieve appropriate database connection parameters for a given tenant

== CollectionSpace data ecosystem terms/concepts

=== data hash

A data structure like:

[src,ruby]
----
{
  'objectnumber'=>'2022.1.6',
  'publishto'=>'CollectionSpace Public Browser',
  'objectproductiondategroup'=>'1880s',
  'objectproductionpersonlocal'=>'Jennifer Brown'
}
----

When batch importing from CSV, each row of the CSV is converted into a data hash like this, with the column header (downcased) on the left and the field value from that row on the right. Empty field values are removed from data hashes.

=== record mapper

JSON file extracted from CollectionSpace UI config JSON file (such as available from https://core.collectionspace.org/cspace/core/config.

Contains the basic information needed to convert a <<data hash>> to a CollectionSpace XML record like https://github.com/lyrasis/collectionspace_migration_tools/blob/main/doc/examples/cs.xml[this one].

There is a record mapper for each <<mappable record type>> in each profile.

For authorities, there is a separate record mapper for each authority vocabulary. This is because each authority vocabulary has a separate services API path.

There are also record mappers for:

* objecthierarchy
* authorityhierarchy
* nonhierarchicalrelationship

Record mappers are generated by https://github.com/collectionspace/cspace-config-untangler/[cspace-config-untangler] and can be downloaded/viewed from https://github.com/collectionspace/cspace-config-untangler/tree/main/data/mappers/community_profiles/release_7_0/core[that application's Github repository].

NOTE: In the Data Toolkit, these are modeled as DataConfig with type "record type".

== Application concepts
=== batch

A set of records derived from a given CSV file, mapped to CS XML, and uploaded to S3 for CS ingest. All records in a batch are of one <<mappable record type>> (e.g. collectionobject, person-local, nonhierarchicalrelationship). A batch includes the records and reports generated at various steps of the batch workflow, all of which are written into a batch-specific directory.

=== batches csv

The CSV file recording all active <<batch,batches>>, and used to manage batch workflow. By default, written to `base_dir/batches.csv`

=== duplicate records

Two or more records of the same <<mappable record type>> which have the same value in their <<identifier field>>.

WARNING: Note that we are not comparing the content of records, but only the <<identifier field>> value. Two very different records with the same <<identifier field>> value will be treated as duplicates!

=== identifier field

The human editable/viewable field containing a value serving as a record identifier. `objectnumber` for collection object, `termdisplayname` (initial) for authorities, `acquisitionreferencenumber` for acquisitions, etc. For each mappable_rectype, the `identifier_field` is specified in the `config` section of the JSON <<record mapper>>.

=== mappable record type

Form of record type name corresponding to a JSON <<record mapper>> and service api path for transferring records of that type.

Do `thor rt all` for a list of commands that will show you valid mappable record type values.
